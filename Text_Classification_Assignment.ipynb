{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification Assignment",
      "provenance": [],
      "collapsed_sections": [
        "kLG2VTrnTvYL",
        "XecOwPNorl2W",
        "J4wfHZwQrs-t",
        "a9BPYqunry97",
        "7KMRBJ7zr9HD",
        "UtwSX1FmVPtw",
        "JKiQBwQuVd9k",
        "iUNbvIvnT7ep",
        "dfbEEtXuWXuo",
        "ueIz-A-eWga9",
        "kHzztFd5Wpx_",
        "z58VpwHoasH_",
        "jA28XDA03Q9-",
        "qI23jTyh5XDU"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MbogoriL/text-classification/blob/main/Text_Classification_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF3cTlYmPj-Q"
      },
      "source": [
        "# <font color='#2F4F4F'>AfterWork Data Science: Text Classification with Python - Project</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLG2VTrnTvYL"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 1. Business Understading </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XecOwPNorl2W"
      },
      "source": [
        "### a) Specifying the Research Question\n",
        "\n",
        "Build a text classification model that classifies a given text input as written in english or in dutch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J4wfHZwQrs-t"
      },
      "source": [
        "### b) Defining the Metric for Success\n",
        "\n",
        "Build a classification model with an accuracy of score of atleast 85%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BPYqunry97"
      },
      "source": [
        "### c) Understanding the Context \n",
        "\n",
        "You work as a Computational Linguist for a Global firm, collaborating with Engineers and\n",
        "Researchers in Assistant and Research & Machine Intelligence to develop language\n",
        "understanding models that improve our ability to understand and generate natural\n",
        "language."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KMRBJ7zr9HD"
      },
      "source": [
        "### d) Recording the Experimental Design\n",
        "\n",
        "* Business Understanding\n",
        "* Data Exploration\n",
        "* Data Preparation\n",
        "* Data Modeling and Evaluation\n",
        "* Summary of Findings \n",
        "* Recommendation\n",
        "* Challenges\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtwSX1FmVPtw"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 2. Data Importation</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdQLGhWqVRTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4475b266-86d3-4c01-df12-cc591d1523a7"
      },
      "source": [
        "# Importing the required libraries\n",
        "# ---\n",
        "# \n",
        "import pandas as pd # library for data manipulation\n",
        "import numpy as np  # librariy for scientific computations\n",
        "import re           # regex library to perform text preprocessing\n",
        "import string       # library to work with strings\n",
        "import nltk         # library for natural language processing\n",
        "import scipy        # scientific computing \n",
        "import seaborn as sns # library for data visualisation\n",
        "\n",
        "# to display all columns\n",
        "pd.set_option('display.max.columns', None)\n",
        "\n",
        "# to display the entire contents of a cell\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Library for Stop words\n",
        "!pip3 install wordninja\n",
        "!pip3 install textblob\n",
        "import wordninja \n",
        "from textblob import TextBlob\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')\n",
        "\n",
        "# Library for Lemmatization\n",
        "nltk.download('wordnet')\n",
        "from textblob import Word\n",
        "\n",
        "# Library for Noun count\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "# Library for TD-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer \n",
        "\n",
        "# Library for metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wordninja\n",
            "  Downloading wordninja-2.0.0.tar.gz (541 kB)\n",
            "\u001b[K     |████████████████████████████████| 541 kB 3.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wordninja\n",
            "  Building wheel for wordninja (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wordninja: filename=wordninja-2.0.0-py3-none-any.whl size=541551 sha256=cd3fa8facec2f606bd2016049e2042f3111f429af4a55bd43dd3e78743a56273\n",
            "  Stored in directory: /root/.cache/pip/wheels/dd/3f/eb/a2692e3d2b9deb1487b09ba4967dd6920bd5032bfd9ff7acfc\n",
            "Successfully built wordninja\n",
            "Installing collected packages: wordninja\n",
            "Successfully installed wordninja-2.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i6Tr31PeCK0"
      },
      "source": [
        "# Custom Functions\n",
        "# ---\n",
        "#\n",
        "\n",
        "# Avg. words\n",
        "def avg_word(sentence):\n",
        "  words = sentence.split()\n",
        "  try:\n",
        "    z = (sum(len(word) for word in words)/len(words))\n",
        "  except ZeroDivisionError:\n",
        "    z = 0 \n",
        "  return z\n",
        "\n",
        "# Noun count\n",
        "pos_dic = {\n",
        "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
        "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
        "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
        "    'adj' :  ['JJ','JJR','JJS'],\n",
        "    'adv' : ['RB','RBR','RBS','WRB']\n",
        "}\n",
        "\n",
        "def pos_check(x, flag):\n",
        "    cnt = 0\n",
        "    try:\n",
        "        wiki = TextBlob(x)\n",
        "        for tup in wiki.tags:\n",
        "            ppo = list(tup)[1]\n",
        "            if ppo in pos_dic[flag]:\n",
        "                cnt += 1\n",
        "    except:\n",
        "        pass\n",
        "    return cnt\n",
        "\n",
        "# Subjectivity \n",
        "def get_subjectivity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        subj = textblob.sentiment.subjectivity\n",
        "    except:\n",
        "        subj = 0.0\n",
        "    return subj\n",
        "\n",
        "# Polarity\n",
        "def get_polarity(tweet):\n",
        "    try:\n",
        "        textblob = TextBlob(unicode(tweet, 'utf-8'))\n",
        "        pol = textblob.sentiment.polarity\n",
        "    except:\n",
        "        pol = 0.0\n",
        "    return pol"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "taugd1WVVYBh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "d5ee7c91-a61a-4458-aeeb-42386102bcc1"
      },
      "source": [
        "# loading and previewing the dataset\n",
        "df = pd.read_csv('http://bit.ly/EnglishNDutchDs') \n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                                  text  \\\n",
              "360  Commercial Op kan de Falcon stuwkracht gewichtsverhouding het Falcon ruimtestation inclusief private om waarde te   \n",
              "618                             He was named Nagedzi after Chief Andy Frank, who was his grandfather. His artworks are   \n",
              "873                                           It won both the Norwegian MGP jr contest in September and went on to win   \n",
              "627                       Er zijn in zijn leven verschillende fasen te onderkennen, die aantonen hoe hij kon evolueren   \n",
              "879                      His highestgrossing releases came with the comedydrama Lage Raho Munna Bhai the drama film My   \n",
              "\n",
              "    label  \n",
              "360    nl  \n",
              "618    en  \n",
              "873    en  \n",
              "627    nl  \n",
              "879    en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab831126-b205-4bc3-b105-aa2ebce8b38f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>Commercial Op kan de Falcon stuwkracht gewichtsverhouding het Falcon ruimtestation inclusief private om waarde te</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>618</th>\n",
              "      <td>He was named Nagedzi after Chief Andy Frank, who was his grandfather. His artworks are</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>873</th>\n",
              "      <td>It won both the Norwegian MGP jr contest in September and went on to win</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>627</th>\n",
              "      <td>Er zijn in zijn leven verschillende fasen te onderkennen, die aantonen hoe hij kon evolueren</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>879</th>\n",
              "      <td>His highestgrossing releases came with the comedydrama Lage Raho Munna Bhai the drama film My</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab831126-b205-4bc3-b105-aa2ebce8b38f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab831126-b205-4bc3-b105-aa2ebce8b38f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab831126-b205-4bc3-b105-aa2ebce8b38f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKiQBwQuVd9k"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 3. Data Exploration</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKMZcfxGVo3m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "807318f4-8854-4cd4-9342-d9b2486168f0"
      },
      "source": [
        "# check dataset shape\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1069, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8s9wj4_Vo3r"
      },
      "source": [
        "Our dataset has 1069 records and 2 variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ov8nTc9cVo3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a25e643c-de12-465d-f9c5-d85a76c694f8"
      },
      "source": [
        "# preview variable datatypes\n",
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     object\n",
              "label    object\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COOwPNRPVo3w"
      },
      "source": [
        "Both variables have the data type object. This is fine for the text variable, however for the label, we will need to convert it to a numerical format. We will do this later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE7Ik7ox85g6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "outputId": "3f057aba-d9a6-4eef-d8c4-a1bb57c33d0b"
      },
      "source": [
        "# plotting the distribution of label\n",
        "sns.countplot(df['label']);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hv9z0csQX5C9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd01b4d-60bd-4ba2-a1cd-64d3605e3c2a"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nl    535\n",
              "en    534\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABx4lS8HZDxp"
      },
      "source": [
        "From above, we can see that our dataset is unbalanced thus we will need to sample equal no. of records for each label during data preparation to make a balanced dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUNbvIvnT7ep"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 4. Data Preparation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfbEEtXuWXuo"
      },
      "source": [
        "### <font color='#2F4F4F'>3.1 Data Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLde07_NVo3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476111bc-748e-4c58-be26-9a341d2ada49"
      },
      "source": [
        "# check for duplicates\n",
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eY9eV5l6V_Xv"
      },
      "source": [
        "There are 10 duplicates. We will need to drop these."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQLb6TqVVo3z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81934bc-694c-40dd-efdc-2ce24bf02f52"
      },
      "source": [
        "# check for missing values\n",
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npaYUA7bVo33"
      },
      "source": [
        "No missing values found. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZGm8pnHWGrb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "081b0a02-d154-44ff-8e3b-d8cd30e47140"
      },
      "source": [
        "# dropping our duplicates\n",
        "df = df.drop_duplicates()\n",
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1059, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0IQmdGugKGF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11bf6200-a06e-438c-fc26-e55dc6132ad7"
      },
      "source": [
        "# What values are in our label variable?\n",
        "# ---\n",
        "#\n",
        "df.label.unique()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['en', 'nl'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzZsUs0FZDRU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1061b92b-741e-4148-e09b-01542db02f91"
      },
      "source": [
        "# sampling text with en \n",
        "df_en = df[df[\"label\"] == 'en'] \n",
        "df_en = df_en.sample(200)\n",
        "\n",
        "# sampling text with nl \n",
        "df_nl = df[df[\"label\"] == 'nl'] \n",
        "df_nl = df_nl.sample(200)\n",
        "\n",
        "# combining our dataframes\n",
        "df = pd.concat([df_en, df_nl])\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                           text  \\\n",
              "964  The concept of evolving capacities is employed internationally as a direct alternative to popular concepts   \n",
              "503                description languages. In 2005, the 1985 paper in which the Yale shooting scenario was first   \n",
              "608                                     this is just a sample sentence you should just ignore it,don't read it.   \n",
              "70        coalition declined which Secretary-General and 1990. a an election growing introducing by Mandela and   \n",
              "861                                         He was part of the team that reached the FA Cup Final and was twice   \n",
              "\n",
              "    label  \n",
              "964    en  \n",
              "503    en  \n",
              "608    en  \n",
              "70     en  \n",
              "861    en  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b36df98d-e5aa-4188-b15e-1ae08f68ece1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>964</th>\n",
              "      <td>The concept of evolving capacities is employed internationally as a direct alternative to popular concepts</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>description languages. In 2005, the 1985 paper in which the Yale shooting scenario was first</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>608</th>\n",
              "      <td>this is just a sample sentence you should just ignore it,don't read it.</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>coalition declined which Secretary-General and 1990. a an election growing introducing by Mandela and</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>861</th>\n",
              "      <td>He was part of the team that reached the FA Cup Final and was twice</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b36df98d-e5aa-4188-b15e-1ae08f68ece1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b36df98d-e5aa-4188-b15e-1ae08f68ece1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b36df98d-e5aa-4188-b15e-1ae08f68ece1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iu0mUgQgfNxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b3250de-9af7-4df3-c346-54b7bf85b4d3"
      },
      "source": [
        "# investigating the label distribution\n",
        "df['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "en    200\n",
              "nl    200\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SABEvQqbfXHF"
      },
      "source": [
        "We now have our balanced dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueIz-A-eWga9"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.2 Text Cleaning</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATi3KYKuWtJ5"
      },
      "source": [
        "# We will create a custom function that will contain all the text cleaning \n",
        "# techniques. We can then reuse the same function for cleaning new data\n",
        "# without rewriting the code.\n",
        "# ---\n",
        "def text_cleaning(text):\n",
        "  # Removing url/links\n",
        "  df['text'] = df.text.apply(lambda x: re.sub(r'http\\S+|www\\S+|https\\S+','', str(x)))\n",
        "\n",
        "  # Removing @ and # characters and replacing them with space\n",
        "  df['text'] = df.text.str.replace('#',' ')\n",
        "  df['text'] = df.text.str.replace('@',' ') \n",
        "\n",
        "  # Conversion to lowercase \n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "  # Removing punctuation characters\n",
        "  df['text'] = df.text.str.replace('[^\\w\\s]','')\n",
        "\n",
        "  # Removing stop words\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "  # Lemmatization\n",
        "  df['text'] = df.text.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()])) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXhae-QrhX85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "54752643-3c56-45ed-80dc-73a9dc8702cc"
      },
      "source": [
        "# Applying the text_cleaning function to our dataframe.\n",
        "# ---\n",
        "# NB: This process may take 5-10 min.\n",
        "# ---\n",
        "#\n",
        "df['text'].apply(text_cleaning)\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                                  text  \\\n",
              "978                         keating remained organized reserve corp wartime service promoted brigadier   \n",
              "192                                            resistance pure preceding improves used ii high contact   \n",
              "1059  op zonnige veen die drassige graslanden moerassen areaal al en bewoner kwelplekken vermeerdering   \n",
              "1010                                 line operated many different company marketed norway bussekspress   \n",
              "355                  deel exclusief de falcon 29e dragon meerdere rakettypen dragon een van met spacex   \n",
              "\n",
              "     label  \n",
              "978     en  \n",
              "192     en  \n",
              "1059    nl  \n",
              "1010    en  \n",
              "355     nl  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f25de3bf-cc04-4327-89ab-fb9cf689913c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>978</th>\n",
              "      <td>keating remained organized reserve corp wartime service promoted brigadier</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>resistance pure preceding improves used ii high contact</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1059</th>\n",
              "      <td>op zonnige veen die drassige graslanden moerassen areaal al en bewoner kwelplekken vermeerdering</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1010</th>\n",
              "      <td>line operated many different company marketed norway bussekspress</td>\n",
              "      <td>en</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>deel exclusief de falcon 29e dragon meerdere rakettypen dragon een van met spacex</td>\n",
              "      <td>nl</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f25de3bf-cc04-4327-89ab-fb9cf689913c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f25de3bf-cc04-4327-89ab-fb9cf689913c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f25de3bf-cc04-4327-89ab-fb9cf689913c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHzztFd5Wpx_"
      },
      "source": [
        "### <font color='#2F4F4F'> 3.3 Feature Engineering</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91ZkaNK4Wth2"
      },
      "source": [
        "# We will create a custom function that will contain all the \n",
        "# feature engineering techniques. We can then use this function \n",
        "# for cleaning new data. \n",
        "# ---\n",
        "\n",
        "def feature_engineering(text):\n",
        "  # Length of tweet\n",
        "  df['length_of_tweet'] = df.text.str.len()\n",
        "\n",
        "  # Word count \n",
        "  df['word_count'] = df.text.apply(lambda x: len(str(x).split(\" \")))\n",
        "\n",
        "  # Word density (Average no. of words / tweet)\n",
        "  df['avg_word_length'] = df.text.apply(lambda x: avg_word(x)) \n",
        "  \n",
        "  # Noun Count\n",
        "  df['noun_count'] = df.text.apply(lambda x: pos_check(x, 'noun'))\n",
        "\n",
        "  # Verb Count\n",
        "  df['verb_count'] = df.text.apply(lambda x: pos_check(x, 'verb'))\n",
        "\n",
        "  # Adjective Count / Tweet\n",
        "  df['adj_count'] = df.text.apply(lambda x: pos_check(x, 'adj'))\n",
        "\n",
        "  # Adverb Count / Tweet\n",
        "  df['adv_count'] = df.text.apply(lambda x: pos_check(x, 'adv'))\n",
        "\n",
        "  # Pronoun \n",
        "  df['pron_count'] = df.text.apply(lambda x: pos_check(x, 'pron'))\n",
        "\n",
        "  # Subjectivity \n",
        "  df['subjectivity'] = df.text.apply(get_subjectivity)\n",
        "\n",
        "  # Polarity\n",
        "  df['polarity'] = df.text.apply(get_polarity)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dli-H5lNjESt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "e4c863e6-1692-45b5-a79f-7d6f38a47666"
      },
      "source": [
        "# Applying the custom feature engineering function to our dataframe.\n",
        "# This process may take 2-5 min.\n",
        "# ---\n",
        "#\n",
        "df.text.apply(feature_engineering)\n",
        "df.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                                              text  \\\n",
              "728  guiguzi wordt de traditionele chinese godsdienst vereerd al een god met de naam wangchanlaozu   \n",
              "977                            office managed lendlease program china burma india theater promoted   \n",
              "667                   four year old learning classical music jazz church also learned gospel music   \n",
              "810           bij de natte variant wet cupping ook wel natte bloedige koppen hijama oftewel zuigen   \n",
              "492                     nick gekomen kubus al en het kubus clint dezelfde hun zijn de barton aarde   \n",
              "\n",
              "    label  length_of_tweet  word_count  avg_word_length  noun_count  \\\n",
              "728    nl               93          14         5.714286           6   \n",
              "977    en               67           9         6.555556           4   \n",
              "667    en               76          12         5.416667           5   \n",
              "810    nl               84          14         5.071429           9   \n",
              "492    nl               74          14         4.357143           8   \n",
              "\n",
              "     verb_count  adj_count  adv_count  pron_count  subjectivity  polarity  \n",
              "728           0          3          0           0           0.0       0.0  \n",
              "977           2          2          0           0           0.0       0.0  \n",
              "667           1          4          1           0           0.0       0.0  \n",
              "810           2          1          0           0           0.0       0.0  \n",
              "492           1          2          0           0           0.0       0.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1922c819-63da-4d5d-ac7c-11f25beae1bf\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>length_of_tweet</th>\n",
              "      <th>word_count</th>\n",
              "      <th>avg_word_length</th>\n",
              "      <th>noun_count</th>\n",
              "      <th>verb_count</th>\n",
              "      <th>adj_count</th>\n",
              "      <th>adv_count</th>\n",
              "      <th>pron_count</th>\n",
              "      <th>subjectivity</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>728</th>\n",
              "      <td>guiguzi wordt de traditionele chinese godsdienst vereerd al een god met de naam wangchanlaozu</td>\n",
              "      <td>nl</td>\n",
              "      <td>93</td>\n",
              "      <td>14</td>\n",
              "      <td>5.714286</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>977</th>\n",
              "      <td>office managed lendlease program china burma india theater promoted</td>\n",
              "      <td>en</td>\n",
              "      <td>67</td>\n",
              "      <td>9</td>\n",
              "      <td>6.555556</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>667</th>\n",
              "      <td>four year old learning classical music jazz church also learned gospel music</td>\n",
              "      <td>en</td>\n",
              "      <td>76</td>\n",
              "      <td>12</td>\n",
              "      <td>5.416667</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>810</th>\n",
              "      <td>bij de natte variant wet cupping ook wel natte bloedige koppen hijama oftewel zuigen</td>\n",
              "      <td>nl</td>\n",
              "      <td>84</td>\n",
              "      <td>14</td>\n",
              "      <td>5.071429</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>nick gekomen kubus al en het kubus clint dezelfde hun zijn de barton aarde</td>\n",
              "      <td>nl</td>\n",
              "      <td>74</td>\n",
              "      <td>14</td>\n",
              "      <td>4.357143</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1922c819-63da-4d5d-ac7c-11f25beae1bf')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1922c819-63da-4d5d-ac7c-11f25beae1bf button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1922c819-63da-4d5d-ac7c-11f25beae1bf');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPUG6EiQjN3B"
      },
      "source": [
        "# Performing further feature engineering techniques\n",
        "# ---\n",
        "#\n",
        "# Feature Construction: Word Level N-Gram TF-IDF Feature \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_word_vect = tfidf.fit_transform(df.text) \n",
        "\n",
        "# Feature Construction: Character Level N-Gram TF-IDF \n",
        "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='char', ngram_range=(1,3),  stop_words= 'english')\n",
        "df_char_vect = tfidf.fit_transform(df.text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU5dGj1_jO8B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f5fd5a-bcbb-410f-edd9-d0f0df557fc4"
      },
      "source": [
        "# Let's prepare the constructed features for modeling\n",
        "# ---\n",
        "# We will select all variables but the target (which is the label) and text variables \n",
        "# ---\n",
        "#  \n",
        "X_metadata = np.array(df[df.columns.difference(['label', 'text'])])\n",
        "X_metadata"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 3.        ,  1.        ,  8.55555556, ...,  0.        ,\n",
              "         2.        ,  9.        ],\n",
              "       [ 0.        ,  1.        ,  6.33333333, ...,  0.        ,\n",
              "         1.        ,  9.        ],\n",
              "       [ 1.        ,  0.        ,  6.        , ...,  0.        ,\n",
              "         0.        ,  5.        ],\n",
              "       ...,\n",
              "       [ 1.        ,  0.        ,  4.13333333, ...,  0.        ,\n",
              "         1.        , 15.        ],\n",
              "       [ 4.        ,  0.        ,  6.6       , ...,  0.        ,\n",
              "         1.        , 15.        ],\n",
              "       [ 2.        ,  0.        ,  6.16666667, ...,  0.        ,\n",
              "         1.        , 12.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8F3QQ6PjZsc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b3c367c-e1a2-4560-99af-1347e82ad809"
      },
      "source": [
        "# We combine our two tfidf (sparse) matrices and X_metadata\n",
        "# ---\n",
        "#\n",
        "X = scipy.sparse.hstack([df_word_vect, df_char_vect, X_metadata])\n",
        "X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<400x2010 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 52569 stored elements in COOrdinate format>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-YdQkYqoYjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a76695c1-1041-48b8-eb08-c2ed21c7f3b3"
      },
      "source": [
        "# Label Preparation i.e. replacing categorial values with numerical ones\n",
        "# ---  \n",
        "y = np.array(df['label'].replace(['nl', 'en'], ['0','1']))\n",
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1',\n",
              "       '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0',\n",
              "       '0', '0', '0', '0', '0', '0', '0', '0', '0', '0'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58VpwHoasH_"
      },
      "source": [
        "##  <font color='#2F4F4F'>Step 5. Data Modeling</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKm33MJYasH_"
      },
      "source": [
        "We will carry out 10 types of classification analysis, namely:\n",
        "1.  Logistic Regression\n",
        "3.  Decision Trees Classification\n",
        "4.  Support Vector Machine (SVM) Classification\n",
        "5. K-Nearest Neighbors (KNN) Classification\n",
        "6.  Gaussian Naive Bayes (NB) Classification\n",
        "7.  BaggingClassifier\n",
        "8.  RandomForestClassifier\n",
        "9.  AdaBoostClassifier\n",
        "10. GradientBoostingClassifier\n",
        "\n",
        "We use their default parameters then compare the different classification models to assess the best performing one(s). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kByQ2gGOasIN"
      },
      "source": [
        "# splitting into 80-20 train-test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3hBaXKTasIV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4451277-83bb-4fc9-9d3b-69a37f6886dc"
      },
      "source": [
        "# loading our classification libraries\n",
        "from sklearn.linear_model import LogisticRegression      # Logistic Regression Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier          # Decision Tree Classifier\n",
        "from sklearn.svm import SVC                              # SVM Classifier\n",
        "from sklearn.naive_bayes import MultinomialNB            # Naive Bayes Classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier       # KNN Classifier\n",
        "\n",
        "# Ensemble classifiers\n",
        "from sklearn.ensemble import BaggingClassifier           # Bagging Meta-Estimator Classifier\n",
        "from sklearn.ensemble import RandomForestClassifier      # RandomForest Classifier \n",
        "from sklearn.ensemble import AdaBoostClassifier          # AdaBoost Classifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # AdaBoost GradientBoostingClassifier\n",
        "import xgboost as xgb                                    # Importing the XGBoost library\n",
        "\n",
        "# instantiating our classifiers\n",
        "logistic_classifier = LogisticRegression(solver='saga', max_iter=800, multi_class='multinomial')\n",
        "decision_classifier = DecisionTreeClassifier(random_state=42)\n",
        "svm_classifier = SVC()\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "naive_classifier = MultinomialNB() \n",
        "\n",
        "bagging_meta_classifier = BaggingClassifier()\n",
        "random_forest_classifier = RandomForestClassifier()\n",
        "ada_boost_classifier = AdaBoostClassifier(random_state=42)\n",
        "gbm_classifier = GradientBoostingClassifier(random_state=42) \n",
        "xg_boost_classifier = xgb.XGBClassifier() \n",
        "\n",
        "\n",
        "# fitting our classifiers to the training data\n",
        "logistic_classifier.fit(X_train, y_train)\n",
        "decision_classifier.fit(X_train, y_train)\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "naive_classifier.fit(X_train, y_train) \n",
        "\n",
        "bagging_meta_classifier.fit(X_train, y_train)\n",
        "random_forest_classifier.fit(X_train, y_train)\n",
        "ada_boost_classifier.fit(X_train, y_train)\n",
        "gbm_classifier.fit(X_train, y_train)\n",
        "xg_boost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# making predictions\n",
        "logistic_y_prediction = logistic_classifier.predict(X_test) \n",
        "decision_y_prediction = decision_classifier.predict(X_test) \n",
        "svm_y_prediction = svm_classifier.predict(X_test) \n",
        "knn_y_prediction = knn_classifier.predict(X_test) \n",
        "naive_y_prediction = naive_classifier.predict(X_test)  \n",
        "\n",
        "bagging_y_classifier = bagging_meta_classifier.predict(X_test) \n",
        "random_forest_y_classifier = random_forest_classifier.predict(X_test) \n",
        "ada_boost_y_classifier = ada_boost_classifier.predict(X_test)\n",
        "gbm_y_classifier = gbm_classifier.predict(X_test)\n",
        "xg_boost_y_classifier = xg_boost_classifier.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfXCA87-asIf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a4b1e7-a11d-45ba-e43e-4fa17226676d"
      },
      "source": [
        "# Evaluating the Models\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Accuracy scores\n",
        "#\n",
        "print(\"Logistic Regression Classifier\", accuracy_score(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", accuracy_score(decision_y_prediction, y_test))\n",
        "print(\"SVN Classifier\", accuracy_score(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", accuracy_score(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", accuracy_score(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", accuracy_score(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", accuracy_score(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", accuracy_score(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", accuracy_score(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", accuracy_score(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier 0.9625\n",
            "Decision Trees Classifier 0.9625\n",
            "SVN Classifier 0.8375\n",
            "KNN Classifier 0.9375\n",
            "Naive Bayes Classifier 0.925\n",
            "Bagging Classifier 0.975\n",
            "Random Forest Classifier 1.0\n",
            "Ada Boost Classifier 1.0\n",
            "GBM Classifier 0.975\n",
            "XGBoost Classifier 0.9875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZ0H_nXpo-lK"
      },
      "source": [
        "Your observation about the performance of the models..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyF5hh38pu5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e517c5e5-51c2-44ed-89ae-9130c9907ae7"
      },
      "source": [
        "# Confusion matrices\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print('Logistic Regression Classifier:') \n",
        "print(confusion_matrix(logistic_y_prediction, y_test))\n",
        "\n",
        "print('Decision Trees Classifier:')\n",
        "print(confusion_matrix(decision_y_prediction, y_test))\n",
        "\n",
        "print('SVN Classifier:')\n",
        "print(confusion_matrix(svm_y_prediction, y_test))\n",
        "\n",
        "print('KNN Classifier:')\n",
        "print(confusion_matrix(knn_y_prediction, y_test))\n",
        "\n",
        "print('Naive Bayes Classifier:')\n",
        "print(confusion_matrix(naive_y_prediction, y_test))\n",
        " \n",
        "print('Bagging Classifier:')\n",
        "print(confusion_matrix(bagging_y_classifier, y_test))\n",
        "\n",
        "print('Random Forest Classifier:')\n",
        "print(confusion_matrix(random_forest_y_classifier, y_test))\n",
        "\n",
        "print('Ada Boost Classifier:')\n",
        "print(confusion_matrix(ada_boost_y_classifier, y_test))\n",
        "\n",
        "print('GBM Classifier:')\n",
        "print(confusion_matrix(gbm_y_classifier, y_test))\n",
        "\n",
        "print('XGBoost Classifier:')\n",
        "print(confusion_matrix(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier:\n",
            "[[35  2]\n",
            " [ 1 42]]\n",
            "Decision Trees Classifier:\n",
            "[[34  1]\n",
            " [ 2 43]]\n",
            "SVN Classifier:\n",
            "[[35 12]\n",
            " [ 1 32]]\n",
            "KNN Classifier:\n",
            "[[34  3]\n",
            " [ 2 41]]\n",
            "Naive Bayes Classifier:\n",
            "[[36  6]\n",
            " [ 0 38]]\n",
            "Bagging Classifier:\n",
            "[[35  1]\n",
            " [ 1 43]]\n",
            "Random Forest Classifier:\n",
            "[[36  0]\n",
            " [ 0 44]]\n",
            "Ada Boost Classifier:\n",
            "[[36  0]\n",
            " [ 0 44]]\n",
            "GBM Classifier:\n",
            "[[35  1]\n",
            " [ 1 43]]\n",
            "XGBoost Classifier:\n",
            "[[35  0]\n",
            " [ 1 44]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBJJqpvjp_Nl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7f3bdc-43db-49c6-eec1-2804dada6358"
      },
      "source": [
        "# Classification Reports\n",
        "from sklearn.metrics import classification_report\n",
        "print(\"Logistic Regression Classifier\", classification_report(logistic_y_prediction, y_test))\n",
        "print(\"Decision Trees Classifier\", classification_report(decision_y_prediction, y_test))\n",
        "print(\"SVM Classifier\", classification_report(svm_y_prediction, y_test))\n",
        "print(\"KNN Classifier\", classification_report(knn_y_prediction, y_test))\n",
        "print(\"Naive Bayes Classifier\", classification_report(naive_y_prediction, y_test))\n",
        " \n",
        "print(\"Bagging Classifier\", classification_report(bagging_y_classifier, y_test))\n",
        "print(\"Random Forest Classifier\", classification_report(random_forest_y_classifier, y_test))\n",
        "print(\"Ada Boost Classifier\", classification_report(ada_boost_y_classifier, y_test))\n",
        "print(\"GBM Classifier\", classification_report(gbm_y_classifier, y_test))\n",
        "print(\"XGBoost Classifier\", classification_report(xg_boost_y_classifier, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96        37\n",
            "           1       0.95      0.98      0.97        43\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.96      0.96      0.96        80\n",
            "weighted avg       0.96      0.96      0.96        80\n",
            "\n",
            "Decision Trees Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96        35\n",
            "           1       0.98      0.96      0.97        45\n",
            "\n",
            "    accuracy                           0.96        80\n",
            "   macro avg       0.96      0.96      0.96        80\n",
            "weighted avg       0.96      0.96      0.96        80\n",
            "\n",
            "SVM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.74      0.84        47\n",
            "           1       0.73      0.97      0.83        33\n",
            "\n",
            "    accuracy                           0.84        80\n",
            "   macro avg       0.85      0.86      0.84        80\n",
            "weighted avg       0.87      0.84      0.84        80\n",
            "\n",
            "KNN Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93        37\n",
            "           1       0.93      0.95      0.94        43\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.94      0.94      0.94        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Naive Bayes Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.86      0.92        42\n",
            "           1       0.86      1.00      0.93        38\n",
            "\n",
            "    accuracy                           0.93        80\n",
            "   macro avg       0.93      0.93      0.92        80\n",
            "weighted avg       0.94      0.93      0.92        80\n",
            "\n",
            "Bagging Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        36\n",
            "           1       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.97      0.97        80\n",
            "weighted avg       0.97      0.97      0.97        80\n",
            "\n",
            "Random Forest Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        36\n",
            "           1       1.00      1.00      1.00        44\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "Ada Boost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        36\n",
            "           1       1.00      1.00      1.00        44\n",
            "\n",
            "    accuracy                           1.00        80\n",
            "   macro avg       1.00      1.00      1.00        80\n",
            "weighted avg       1.00      1.00      1.00        80\n",
            "\n",
            "GBM Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97        36\n",
            "           1       0.98      0.98      0.98        44\n",
            "\n",
            "    accuracy                           0.97        80\n",
            "   macro avg       0.97      0.97      0.97        80\n",
            "weighted avg       0.97      0.97      0.97        80\n",
            "\n",
            "XGBoost Classifier               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99        35\n",
            "           1       1.00      0.98      0.99        45\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jA28XDA03Q9-"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 6. Summary of Findings and Recommendation</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our best performing models were random forest and ada boost classification. To improve our model, we can try perfoming other text processing techniques that would better prepare our data for fitting our model. We can also perform hyperparameter tuning and sample a balanced dataset."
      ],
      "metadata": {
        "id": "UsXRa2goBUQO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI23jTyh5XDU"
      },
      "source": [
        "## <font color='#2F4F4F'>Step 7. Challenging our Solution</font>"
      ]
    }
  ]
}